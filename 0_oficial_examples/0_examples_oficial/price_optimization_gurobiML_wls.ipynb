{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24843c7d",
   "metadata": {
    "id": "24843c7d"
   },
   "source": [
    "# Do you have a Gurobi WLS?\n",
    "Use the cell below to add your license information and carry on.\n",
    "\n",
    "If you don't, no problem. You can work though a lighter version of this notebook using a [free limited license here](https://colab.research.google.com/github/Gurobi/modeling-examples/blob/master/price_optimization/price_optimization_gurobiML.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceZ4PV542EgN",
   "metadata": {
    "id": "ceZ4PV542EgN"
   },
   "outputs": [],
   "source": [
    "\n",
    "params = {\n",
    "\"WLSACCESSID\": ---- ,\n",
    "\"WLSSECRET\":  ---- ,\n",
    "\"LICENSEID\": ---- ,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a00ac5",
   "metadata": {
    "id": "94a00ac5"
   },
   "source": [
    "# Part Two: Avocado Pricing and Supply Using Mathematical Optimization\n",
    "\n",
    "This is a second part of an example on price optimization: [How Much Is Too Much? Avocado Pricing and Supply Using Mathematical Optimization](https://github.com/Gurobi/modeling-examples/tree/master/price_optimization)\n",
    "\n",
    "In the first part, an ordinary linear regression model (OLS) was used to establish the relationship between price and demand based on data from the [Hass Avocado Board](https://hassavocadoboard.com/) (HAB).\n",
    "\n",
    "Part Two replaces the OLS model with a trained `Scikit-learn` model and uses the [Gurobi Machine Learning](https://gurobi-machinelearning.readthedocs.io/en/stable/#) package to embed it in a Gurobi optimization model.\n",
    "\n",
    "In this example, we will also use `gurobipy-pandas`, which is another Gurobi open-source package and serves as a convenient (and optional) wrapper to connect pandas with gurobipy.\n",
    "\n",
    "If you are already familiar with the example from the other notebook, you can jump directly to [building the regression model](#Part-2:-Predict-the-Sales)\n",
    "and then to [formulating the optimization problem](#Part-3:-Optimize-for-Price-and-Supply-of-Avocados).\n",
    "\n",
    "**Goal**: Develop a data science and decision-making pipeline for pricing and distribution of avocados to maximize revenue.\n",
    "\n",
    "To accomplish this, the notebook will walk trough three stages:\n",
    "\n",
    "1. A quick review of the HAB data\n",
    "2. Build a prediction model for avocado demand as a function of price, region, year and seasonality.\n",
    "3. Design an optimization model that sets the optimal price and supply quantity to maximize the net revenue while incorporating transportation and costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716ed7e0",
   "metadata": {
    "id": "716ed7e0"
   },
   "source": [
    "## Load the Packages and Prepare the Dataset\n",
    "\n",
    "Just as in the first example, we use real HAB sales data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff1bfa",
   "metadata": {
    "id": "b1ff1bfa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408e66ab",
   "metadata": {
    "id": "408e66ab"
   },
   "source": [
    "The dataset from HAB contains sales data for the years 2019-2022. This data is augmented by a previous download from HAB available on\n",
    "[Kaggle](https://www.kaggle.com/datasets/timmate/avocado-prices-2020) with sales for the years 2015-2018.\n",
    "\n",
    "This notebook will skip a lot of the preprocessing from the first version of this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-bbhXnJqFlu2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "-bbhXnJqFlu2",
    "outputId": "040eae83-b932-4408-c873-58c7b8d0a80c"
   },
   "outputs": [],
   "source": [
    "data_url = \"https://raw.githubusercontent.com/Gurobi/modeling-examples/master/price_optimization/\"\n",
    "avocado = pd.read_csv(data_url+\"HAB_data_2015to2022.csv\")\n",
    "avocado[\"date\"] = pd.to_datetime(avocado[\"date\"])\n",
    "avocado = avocado.sort_values(by=\"date\")\n",
    "avocado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91caa2",
   "metadata": {
    "id": "3a91caa2"
   },
   "source": [
    "One of the regions in the above data frame is `Total_US`, so we can create a list of regions, excluding the total, which can be used to subset the data now. It'll be used later in the example as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f6cc22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "c2f6cc22",
    "outputId": "1d39e71c-6025-48e1-eea3-ba3f1a785c63"
   },
   "outputs": [],
   "source": [
    "regions = [\n",
    "    \"Great_Lakes\",\n",
    "    \"Midsouth\",\n",
    "    \"Northeast\",\n",
    "    \"Northern_New_England\",\n",
    "    \"SouthCentral\",\n",
    "    \"Southeast\",\n",
    "    \"West\",\n",
    "    \"Plains\"\n",
    "]\n",
    "df = avocado[(avocado.region.isin(regions))] # & (avocado.peak==0)\n",
    "df.drop(columns=['date']) #,'peak'\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "r_plt = sns.scatterplot(data=df, x='price', y='units_sold', hue='region')\n",
    "r_plt.legend(fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5186fd3e",
   "metadata": {
    "id": "5186fd3e"
   },
   "source": [
    "## Predict the Sales\n",
    "\n",
    "In the first instance of this example, further analysis was done on the input data along with a few visualizations. Here, we will go directly to the predicive model training, starting with a random split of the dataset into $70\\%$ training and $30\\%$ testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866c540b",
   "metadata": {
    "id": "866c540b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[[\"region\", \"price\", \"year\", \"peak\"]]\n",
    "y = df[\"units_sold\"]\n",
    "# Split the data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.7, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071154e3",
   "metadata": {
    "id": "071154e3"
   },
   "source": [
    "Note that the region is a categorical variable and we will transform that variable using Scikit Learn's `OneHotEncoder`. We also use a standard scaler for prices and year index, combining all of the ese with `Column Transformer` built using `make_column_transformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c7c565",
   "metadata": {
    "id": "71c7c565"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "feat_transform = make_column_transformer(\n",
    "    (OneHotEncoder(drop=\"first\"), [\"region\"]),\n",
    "    (StandardScaler(), [\"price\", \"year\"]),\n",
    "    (\"passthrough\", [\"peak\"]),\n",
    "    verbose_feature_names_out=False,\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b6bcaa",
   "metadata": {
    "id": "65b6bcaa"
   },
   "source": [
    "The regression model is a pipeline consisting of the `Column Transformer` and the type of model we want to use for the regression. For comparison, we'll stick with a linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16294bfb",
   "metadata": {
    "id": "16294bfb"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29AoNyWVdfH0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29AoNyWVdfH0",
    "outputId": "38d8a6fd-a476-4fff-ac05-04595e7727b9"
   },
   "outputs": [],
   "source": [
    "reg = make_pipeline(feat_transform, LinearRegression())\n",
    "scores = cross_val_score(reg, X_train, y_train, cv=5)\n",
    "print(\"%0.4f R^2 with a standard deviation of %0.4f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XE-H4se_9-Cx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XE-H4se_9-Cx",
    "outputId": "af14ccad-5edb-45e4-f001-145088376d17"
   },
   "outputs": [],
   "source": [
    "# Find model score on test data\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "print(f\"The R^2 value in the test set is {np.round(r2_score(y_test, y_pred),5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3291d28d",
   "metadata": {
    "id": "3291d28d"
   },
   "source": [
    "We can observe a good $R^2$ value in the test set. We will now train the fit to the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b956503",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1b956503",
    "outputId": "5224b188-a568-44ae-fd0a-6d83de502944"
   },
   "outputs": [],
   "source": [
    "reg.fit(X, y)\n",
    "y_pred_full = reg.predict(X)\n",
    "print(f\"The R^2 value in the full dataset is {np.round(r2_score(y, y_pred_full),5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y5mj6_edLl5x",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 619
    },
    "id": "y5mj6_edLl5x",
    "outputId": "2686de0d-8d3b-4c7a-b871-415ed5e878ea"
   },
   "outputs": [],
   "source": [
    "year = 2019\n",
    "peak_or_not = 1\n",
    "fig, axs = plt.subplots(4, 2, figsize=(10, 7))\n",
    "\n",
    "for k in range(8):\n",
    "  r = regions[k]\n",
    "  i = k//2\n",
    "  j = k%2\n",
    "  X_r = df.loc[(df.region==r) & (df.peak==peak_or_not),[\"price\", \"year\",\"units_sold\"]]\n",
    "  x_plt = X_r.price\n",
    "  p_new = np.linspace(.9*min(x_plt),1.1*max(x_plt),50)\n",
    "  x_new = pd.DataFrame(\n",
    "      data={\n",
    "          \"year\": year,\n",
    "          \"peak\": peak_or_not,\n",
    "          \"region\": r,\n",
    "          \"price\": p_new\n",
    "      },\n",
    "      index=range(50)\n",
    "  )\n",
    "  x_new['units_sold'] = reg.predict(x_new)\n",
    "  sns.lineplot(data=x_new, x='price', y='units_sold', c='orange', ax=axs[i,j])\n",
    "  sns.scatterplot(data=X_r, x='price', y='units_sold', legend=0, ax=axs[i,j])\n",
    "  axs[i, j].legend(title=r, loc='upper right', prop={'size': 3}, handles = []);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93868dba",
   "metadata": {
    "id": "93868dba"
   },
   "source": [
    "## Optimize for Price and Supply of Avocados\n",
    "\n",
    "Here is a quick review of notation for the formulation of the mathematical optimization model. The subscript $r$ will be used to denote each region.\n",
    "### Input parameters\n",
    "- $d(p,r)$: predicted demand in region $r$ when the avocado price is $p$\n",
    "- $B$: available avocados to be distributed across the regions\n",
    "- $c_{waste}$: cost ($\\$$) per wasted avocado\n",
    "- $c^r_{transport}$: cost ($\\$$) of transporting a avocado to region $r$\n",
    "- $a_{min},a_{max}$: minimum and maximum price ($\\$$) per avocado\n",
    "- $b^r_{min},b^r_{max}$: minimum and maximum number of avocados allocated to region $r$\n",
    "\n",
    "The following code sets values for these parameters. Feel free to adjust these to see how the solution to the optimization model will change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f293b80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "1f293b80",
    "outputId": "d2a5e86a-993c-4291-96f2-aa16c978b6f7"
   },
   "outputs": [],
   "source": [
    "# Sets and parameters\n",
    "year = 2022\n",
    "B = 30  # total amount of avocado supply\n",
    "peak_or_not = 0  # 1 if it is the peak season; 0 if isn't\n",
    "c_waste = 0.1  # the cost ($) of wasting an avocado\n",
    "# the cost of transporting an avocado\n",
    "c_transport = pd.Series(\n",
    "    {\n",
    "        \"Great_Lakes\": 0.3,\n",
    "        \"Midsouth\": 0.1,\n",
    "        \"Northeast\": 0.4,\n",
    "        \"Northern_New_England\": 0.5,\n",
    "        \"SouthCentral\": 0.3,\n",
    "        \"Southeast\": 0.2,\n",
    "        \"West\": 0.2,\n",
    "        \"Plains\": 0.2,\n",
    "    }, name='transport_cost'\n",
    ")\n",
    "c_transport = c_transport.loc[regions]\n",
    "\n",
    "a_min = 0  # minimum avocado price\n",
    "a_max = 2  # maximum avocado price\n",
    "\n",
    "# Get the lower and upper bounds from the dataset for the price and the number of products to be stocked\n",
    "data = pd.concat([c_transport,\n",
    "                  df.groupby(\"region\")[\"units_sold\"].min().rename('min_delivery'),\n",
    "                  df.groupby(\"region\")[\"units_sold\"].max().rename('max_delivery'),\n",
    "                  df.groupby(\"region\")[\"price\"].max().rename('max_price'),], axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6WbGctoAYUw",
   "metadata": {
    "id": "c6WbGctoAYUw"
   },
   "source": [
    "#### Install and import Gurobi packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z7eyw2klAAcG",
   "metadata": {
    "id": "Z7eyw2klAAcG"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install gurobipy_pandas #this also installs gurobipy\n",
    "%pip install gurobi-machinelearning\n",
    "import gurobipy_pandas as gppd\n",
    "from gurobi_ml import add_predictor_constr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaf9769",
   "metadata": {
    "id": "5eaf9769"
   },
   "source": [
    "### Create dataframe for the fixed features of the regression\n",
    "\n",
    "We now start creating the input of the regression in the optimization models with the features that are fixed and use `gurobipy-pandas` that help to more easily create gurobipy models using pandas data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb83dc2",
   "metadata": {
    "id": "ebb83dc2"
   },
   "source": [
    "First, create a dataframe with the features that are fixed in our optimization problem.\n",
    "It is indexed by the regions (we want to use one regression to predict demand for all  regions) and has the three\n",
    "columns corresponding to the fixed features:\n",
    "\n",
    "* `year`\n",
    "* `peak` with the value of `peak_or_not`\n",
    "* `region` that repeats the names of the regions.\n",
    "\n",
    "Let's display the dataframe to make sure it is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e879833f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "e879833f",
    "outputId": "7eecfabd-8c38-4a4b-81a5-73bdc4f3ac41"
   },
   "outputs": [],
   "source": [
    "feats = pd.DataFrame(\n",
    "    data={\n",
    "        \"year\": year,\n",
    "        \"peak\": peak_or_not,\n",
    "        \"region\": regions,\n",
    "    },\n",
    "    index=regions\n",
    ")\n",
    "feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5103dcd2",
   "metadata": {
    "id": "5103dcd2"
   },
   "source": [
    "### Decision Variables\n",
    "\n",
    "Let us now define the decision variables. In our model, we want to store the\n",
    "price and number of avocados allocated to each region. We also want variables\n",
    "that track how many avocados are predicted to be sold and how many are predicted\n",
    "to be wasted. The following notation is used to model these decision variables.\n",
    "\n",
    "- $p$ the price of an avocado ($\\$$) in each region\n",
    "- $x$ the number of avocados supplied to each region\n",
    "- $s$ the predicted number of avocados sold in each region\n",
    "- $u$ the predicted number of avocados unsold (wasted) in each region\n",
    "- $d$ the predicted demand in each region\n",
    "\n",
    "All those variables are created using gurobipy-pandas, with the function `gppd.add_vars` they are given the same index as the `data` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iRf74HU8ibFU",
   "metadata": {
    "id": "iRf74HU8ibFU"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import gurobipy as gp\n",
    "\n",
    "env = gp.Env(params=params)\n",
    "\n",
    "#Create the model within the Gurobi environment\n",
    "m = gp.Model(\"Avocado_Price_Allocation\", env=env)\n",
    "\n",
    "p = gppd.add_vars(m, data, name=\"price\", lb=a_min, ub=a_max) # price of an avocado for each region 'max_price'\n",
    "x = gppd.add_vars(m, data, name=\"x\", lb='min_delivery', ub='max_delivery') # number of avocados supplied to each reagion\n",
    "s = gppd.add_vars(m, data, name=\"s\") # predicted amount of sales in each region for the given price\n",
    "u = gppd.add_vars(m, data, name=\"w\") # unsold inventory, excess wasteage in each region\n",
    "d = gppd.add_vars(m, data, lb=-gp.GRB.INFINITY, name=\"demand\") # Add variables for the regression\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q0urlvohhqRy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0urlvohhqRy",
    "outputId": "23fced26-9513-4453-ce33-38831ff44cbf"
   },
   "outputs": [],
   "source": [
    "# Display one of the variables\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3bf602",
   "metadata": {
    "id": "5a3bf602"
   },
   "source": [
    "### Add the Supply Constraint\n",
    "\n",
    "We now introduce the constraints. The first constraint is to make sure that the\n",
    "total number of avocados supplied is equal to $B$, which can be mathematically\n",
    "expressed as follows.\n",
    "\n",
    "\\begin{align*} \\sum_{r} x_r &= B \\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c45f9",
   "metadata": {
    "id": "071c45f9"
   },
   "outputs": [],
   "source": [
    "m.addConstr(x.sum() == B)\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59009e4d",
   "metadata": {
    "id": "59009e4d"
   },
   "source": [
    "### Add Constraints That Define Sales Quantity\n",
    "\n",
    "As a quick reminder, the sales quantity is the minimum of the allocated quantity and the predicted demand, i.e., $s_r = \\min \\{x_r,d_r(p_r)\\}$ This relationship can be modeled by the following two constraints for each region $r$.\n",
    "\n",
    "\\begin{align*} s_r &\\leq x_r  \\\\\n",
    "s_r &\\leq d(p_r,r) \\end{align*}\n",
    "\n",
    "In this case, we use gurobipy-pandas `add_constrs` function, which is intuitive to use given the inequalities above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5323898",
   "metadata": {
    "id": "c5323898"
   },
   "outputs": [],
   "source": [
    "gppd.add_constrs(m, s, gp.GRB.LESS_EQUAL, x)\n",
    "gppd.add_constrs(m, s, gp.GRB.LESS_EQUAL, d)\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf71c2f4",
   "metadata": {
    "id": "bf71c2f4"
   },
   "source": [
    "### Add the Wastage Constraints\n",
    "\n",
    "Finally, we should define the predicted unsold number of avocados in each region, given by the supplied quantity that is not predicted to be sold. We can express this\n",
    "mathematically for each region $r$.\n",
    "\n",
    "\\begin{align*} u_r &= x_r - s_r \\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a28ede",
   "metadata": {
    "id": "e3a28ede"
   },
   "outputs": [],
   "source": [
    "gppd.add_constrs(m, u, gp.GRB.EQUAL, x - s)\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0614c0c1",
   "metadata": {
    "id": "0614c0c1"
   },
   "source": [
    "### Add the constraints to predict demand\n",
    "First, we create our full input for the predictor constraint. We concatenate the `p` variables and the fixed features. Remember that the predicted price is a function of region, year, and peak/off-peak season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaf9cea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "efaf9cea",
    "outputId": "29bdfb45-3f3f-47b9-8e7f-5ab78ff685b8"
   },
   "outputs": [],
   "source": [
    "m_feats = pd.concat([feats, p], axis=1)[[\"region\", \"price\", \"year\",\"peak\"]]\n",
    "m_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2dc88f",
   "metadata": {
    "id": "8f2dc88f"
   },
   "source": [
    "Now, we just call\n",
    "[add_predictor_constr](https://gurobi-machinelearning.readthedocs.io/en/stable/api/AbstractPredictorConstr.html#gurobi_ml.add_predictor_constr)\n",
    "to insert the constraints linking the features and the demand into the model `m`.\n",
    "\n",
    "It is important that you keep the columns in the order above, otherwise you will see an error. The columns must be in the same order as the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200c4cb9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "200c4cb9",
    "outputId": "ba0c5830-dbc4-458f-82ea-d959ffcb1b9e"
   },
   "outputs": [],
   "source": [
    "pred_constr = add_predictor_constr(m, reg, m_feats, d)\n",
    "pred_constr.print_stats()\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e15e4ae",
   "metadata": {
    "id": "5e15e4ae"
   },
   "source": [
    "### Set the Objective\n",
    "\n",
    "The goal is to maximize the **net revenue**, which is the product of price and quantity, minus costs over all regions. This model assumes the purchase costs are fixed (since the amount $B$ is fixed) and are therefore not incorporated.\n",
    "\n",
    "Using the defined decision variables, the objective can be written as follows.\n",
    "\n",
    "\\begin{align} \\textrm{maximize} &  \\sum_{r}  (p_r * s_r - c_{waste} * u_r -\n",
    "c^r_{transport} * x_r)& \\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ff1b2",
   "metadata": {
    "id": "703ff1b2"
   },
   "outputs": [],
   "source": [
    "m.setObjective((p * s).sum() - c_waste * u.sum() - (c_transport * x).sum(),\n",
    "               gp.GRB.MAXIMIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadd1721",
   "metadata": {
    "id": "cadd1721"
   },
   "source": [
    "### Fire Up the Solver\n",
    "\n",
    "In our model, the objective is **quadratic** since we take the product of price\n",
    "and the predicted sales, both of which are variables. Maximizing a quadratic\n",
    "term is said to be **non-convex**, and we specify this by setting the value of\n",
    "the [Gurobi NonConvex\n",
    "parameter](https://www.gurobi.com/documentation/10.0/refman/nonconvex.html) to be\n",
    "$2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a42223",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06a42223",
    "outputId": "96cde593-0ed2-4af8-e871-b02cfbbf95f9"
   },
   "outputs": [],
   "source": [
    "m.Params.NonConvex = 2\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3474030",
   "metadata": {
    "id": "b3474030"
   },
   "source": [
    "The solver solved the optimization problem in less than a second. Let us now\n",
    "analyze the optimal solution by storing it in a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d106b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "ec0d106b",
    "outputId": "ce957e65-cf6c-4ee2-cb2b-4a56c6eff9a4"
   },
   "outputs": [],
   "source": [
    "solution = pd.DataFrame(index=regions)\n",
    "\n",
    "solution[\"Price\"] = p.gppd.X\n",
    "solution[\"Historical_Max\"] = data.max_price\n",
    "solution[\"Allocated\"] = x.gppd.X\n",
    "solution[\"Sold\"] = s.gppd.X\n",
    "solution[\"Wasted\"] = u.gppd.X\n",
    "solution[\"Pred_demand\"] = d.gppd.X\n",
    "\n",
    "opt_revenue = m.ObjVal\n",
    "print(\"\\n The optimal net revenue: $%f million\" % opt_revenue)\n",
    "solution.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34279917",
   "metadata": {
    "id": "34279917"
   },
   "source": [
    "We can also check the error in the estimate of the Gurobi solution for the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353149d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "353149d2",
    "outputId": "67064d47-a511-4acc-c83b-b0ec8fec055b"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Maximum error in approximating the regression {:.6}\".format(\n",
    "        np.max(pred_constr.get_error())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zUPgLEOwG5ZF",
   "metadata": {
    "id": "zUPgLEOwG5ZF"
   },
   "source": [
    "## Changing the Regression Model\n",
    "Our regression model has some flaws, so let's try another model type and see how the fit produced, and how that will impact the optimization model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4Z5epMZwHWGD",
   "metadata": {
    "id": "4Z5epMZwHWGD"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qBNoSVQbdfWf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBNoSVQbdfWf",
    "outputId": "81cd7091-118a-4ea9-d5eb-9b0a831b8780"
   },
   "outputs": [],
   "source": [
    "reg = make_pipeline(feat_transform, GradientBoostingRegressor(n_estimators=100, max_leaf_nodes = 20,\n",
    "                                              loss = 'absolute_error', random_state = 123))\n",
    "scores = cross_val_score(reg, X_train, y_train, cv=5)\n",
    "print(\"%0.4f R^2 with a standard deviation of %0.4f\" % (scores.mean(), scores.std()))\n",
    "# Fit to entire training data\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "print(f\"The R^2 value in the test set is {np.round(r2_score(y_test, y_pred),5)}\")\n",
    "reg.fit(X, y)\n",
    "y_pred_full = reg.predict(X)\n",
    "print(f\"The R^2 value in the full dataset is {np.round(r2_score(y, y_pred_full),5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tT56fnUWHZAy",
   "metadata": {
    "id": "tT56fnUWHZAy"
   },
   "source": [
    "Most of the optimization model is unchanged given the new regression model. So to update the optimization we `remove` the previous prediction then add the new one just as we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pzQR12rAr-b_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzQR12rAr-b_",
    "outputId": "cb4ef3b7-6307-4eba-8ef6-0cbe7c80bf0b"
   },
   "outputs": [],
   "source": [
    "pred_constr.remove()\n",
    "pred_constr = add_predictor_constr(m, reg, m_feats, d)\n",
    "pred_constr.print_stats()\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iT7K7gN_HqPn",
   "metadata": {
    "id": "iT7K7gN_HqPn"
   },
   "source": [
    "With the new model created, we can resolve the optimization and extract the new solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7H7Mot0ZHper",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7H7Mot0ZHper",
    "outputId": "4b992dc0-9b4f-4edb-d65d-933d74a3e521"
   },
   "outputs": [],
   "source": [
    "m.optimize()\n",
    "\n",
    "solution = pd.DataFrame(index=regions)\n",
    "\n",
    "solution[\"Price\"] = p.gppd.X\n",
    "solution[\"Max_Price\"] = data.max_price\n",
    "solution[\"Allocated\"] = x.gppd.X\n",
    "solution[\"Sold\"] = s.gppd.X\n",
    "solution[\"Wasted\"] = u.gppd.X\n",
    "solution[\"Pred_demand\"] = d.gppd.X\n",
    "\n",
    "opt_revenue = m.ObjVal\n",
    "print(\"\\n The optimal net revenue: $%f million\" % opt_revenue)\n",
    "solution.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "o8PqZxMSvu05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "o8PqZxMSvu05",
    "outputId": "e0e872da-b742-4917-f4f3-fba130d7c897"
   },
   "outputs": [],
   "source": [
    "solution = pd.DataFrame(index=regions)\n",
    "\n",
    "solution[\"Price\"] = p.gppd.X\n",
    "solution[\"Max_Price\"] = data.max_price\n",
    "solution[\"Allocated\"] = x.gppd.X\n",
    "solution[\"Sold\"] = s.gppd.X\n",
    "solution[\"Wasted\"] = u.gppd.X\n",
    "solution[\"Pred_demand\"] = d.gppd.X\n",
    "\n",
    "opt_revenue = m.ObjVal\n",
    "print(\"\\n The optimal net revenue: $%f million\" % opt_revenue)\n",
    "solution.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gNx8_8INHQzP",
   "metadata": {
    "id": "gNx8_8INHQzP"
   },
   "source": [
    "Check how the new model fits the overall dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F7RZcx1_HP4q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 619
    },
    "id": "F7RZcx1_HP4q",
    "outputId": "f47d0479-d6c3-4821-bcb1-e7fc8b2ccc86"
   },
   "outputs": [],
   "source": [
    "year = 2019\n",
    "fig, axs = plt.subplots(4, 2, figsize=(12, 7))\n",
    "\n",
    "for k in range(8):\n",
    "  r = regions[k]\n",
    "  i = k//2\n",
    "  j = k%2\n",
    "  X_r = df.loc[(df.region==r) & (df.peak==peak_or_not),[\"price\", \"year\",\"units_sold\"]]\n",
    "  x_plt = X_r.price\n",
    "  p_new = np.linspace(.9*min(x_plt),1.1*max(x_plt),50)\n",
    "  x_new = pd.DataFrame(\n",
    "      data={\n",
    "          \"year\": year,\n",
    "          \"peak\": peak_or_not,\n",
    "          \"region\": r,\n",
    "          \"price\": p_new\n",
    "      },\n",
    "      index=range(50)\n",
    "  )\n",
    "  x_new['units_sold'] = reg.predict(x_new)\n",
    "  sns.lineplot(data=x_new, x='price', y='units_sold', c='orange', ax=axs[i,j])\n",
    "  sns.scatterplot(data=X_r, x='price', y='units_sold',legend=0, ax=axs[i,j])\n",
    "  axs[i, j].legend(title=r, loc='upper right', prop={'size': 3}, handles = []);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b4a665",
   "metadata": {
    "id": "c3b4a665"
   },
   "source": [
    "This was in introductory look at using the Gurobi Machine Learning package. For more on this example, see the [Price Optimization example of Github](https://github.com/Gurobi/modeling-examples/tree/master/price_optimization)\n",
    "as well as how to work with the model interactively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9fbba6",
   "metadata": {
    "id": "bc9fbba6",
    "nbsphinx": "hidden"
   },
   "source": [
    "Copyright © 2023 Gurobi Optimization, LLC"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "jupytext": {
   "formats": "ipynb///ipynb,myst///md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "license": {
   "full_text": "# Copyright © 2022 Gurobi Optimization, LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================="
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
